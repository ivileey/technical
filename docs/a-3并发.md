# 并发

## 1.线程和进程的概念

### 进程

- 程序由指令和数据组成，但这些指令要运行，数据要读写，就必须将指令加载至CPU，数据加载至内存。在指令运行过程中还需要用到磁盘、网络等设备。进程就是用来加载指令、管理内存、管理IO的。
- 当一个程序被运行，从磁盘加载这个程序的代码至内存，这时就开启了一个进程。
- 进程就可以视为一个实例。大部分程序可以同时运行多了实例进程（如记事本等）、也有的程序只能启动一个实例进程（网易云音乐）因为他们要使用音响IO设备。在windows中一个.exe程序就是一个进程

### 线程

- 一个进程之内可以分为一到多个线程。
- 一个线程就是一个指令流，将指令流中的一条条指令以一定的顺序交给CPU执行。
- Java中，线程作为最小的调度单位，进程作为资源分配的最小单位。在windows中进程是不活动的，只是作为线程的容器。

### 两者对比

- 进程基本上相互独立的，而线程存在于进程内，是进程的一个子集。
- 线程可以访问进程中的共享资源。
- 进程间通信较为复杂
  - 同一台计算机的进程通信称为IPC
  - 不同计算机之间的进程通信，需要通过网络，并遵守共同的协议，例如HTTP
- 线程通信相对简单，因为它们共享进程内的内存，一个例子是多个线程可以访问同一个共享变量
- 线程更轻量，线程上下文切换成本一般要比进程上下文切换低

（还可以扩展回答一下进程间通信方式，windows和linux中进程和线程的概念）

### 多进程、多线程、多任务（windows vs Linux）

1、Windows下多进程与多线程

Windows中进程只是作为资源的拥有者，并不是实际任务的执行者，实际的执行靠线程实现。一个进程可以拥有多个线程，多个线程共享进程拥有的资源，在具体执行任务时由线程来使用处理机。

Windows中，进程实现靠createProcess实现。而createProcess有一大堆的参数，不过很多时候都默认为null。其作用相当于创建一个进程的同时创建一个线程（一般一个）。

2、Linux下多进程与多线程

Linux的进程创建靠fork实现。在Linux中，进程本身是可以执行的（区别windows）。

fork()的含义是把进程本身clone一个新的出来。也就是说，fork之后子进程和父进程都执行同样的一段代码。想要区分，必须通过fork的返回值来区分。

理论上说Linux内核是没有线程这个概念的，只有内核调度实体(Kernal Scheduling Entry， KSE)这个概念。Linux的线程本质上是一种轻量级的进程，是通过clone系统调用来创建的。

3、java多线程

每启动一个java应用程序，就会启动一个jvm进程。在一个jvm进程中有且只有一个进程。在这个jvm环境中，所有的程序代码都是以线程来运行的。jvm找到程序的入口点main()方法，启动一个主线程。

## 1.1进程间通信的方式

1. 管道，fd[0]用于读,fd[1]用于写

   只支持半双工通信，只能在父子或兄弟进程中使用

2. FIFO，命名管道，去除了管道只能在父子进程中使用的限制

3. 消息队列

   - 消息队列可以独立于读写进程存在，从而避免了 FIFO 中同步管道的打开和关闭时可能产生的困难；
   - 避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法；
   - 读进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收。

4. 信号量：一个计数器，用于为多个进程提供对共享数据对象的访问。

5. 共享存储：

   允许多个进程共享一个给定的存储区。因为数据不需要在进程之间复制，所以这是最快的一种 IPC。

   需要使用信号量用来同步对共享存储的访问。

   多个进程可以将同一个文件映射到它们的地址空间从而实现共享内存。另外 XSI 共享内存不是使用文件，而是使用内存的匿名段。

6. 套接字：可用于不同机器间的进程通信。

## 1.2进程上下文切换会做什么（保存哪些内容，存储在什么地方）

先把前一个进程的CPU上下文（CPU寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳到程序计数器所指的新位置，运行新任务。

而这些保存下来的上下文，会存储在系统内核中，并在任务重新调度执行时再次加载进来。这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行。

进程上下文切换保存的内容有：

1.页表 -- 对应虚拟内存资源
2.文件描述符表/打开文件表 -- 对应打开的文件资源
3.寄存器 -- 对应运行时数据
4.信号控制信息/进程运行信息

进程上下文切换需要切换页表等重量级资源，线程上下文切换只需要切换寄存器等轻量级数据

## 1.3进程地址空间

**程序段(Text):**程序代码在内存中的映射，存放函数体的二进制代码。

**初始化过的数据(Data):**在程序运行初已经对变量进行初始化的数据。

**未初始化过的数据(BSS):**在程序运行初未对变量进行初始化的数据。

**栈(Stack):**存储局部、临时变量，函数调用时，存储函数的返回指针，用于控制函数的调用和返回。在程序块开始时自动分配内存,结束时自动释放内存，其操作方式类似于数据结构中的栈。

**堆 (Heap):**存储动态内存分配,需要程序员手工分配,手工释放.注意它与数据结构中的堆是两回事，分配方式类似于链表。

## 1.4线程共享进程中的哪些资源

堆内存的中的内容

b. 全局变量 它是与具体某一函数无关的，所以也与特定线程无关；因此也是共享的

c. 静态变量 虽然对于局部变量来说，它在代码中是“放”在某一函数中的，但是其存放位置和全局变量一样，存于堆中开辟的.bss和.data段，是共享的

d. 文件等公用资源  这个是共享的，使用这些公共资源的线程必须同步。Win32 提供了几种同步资源的方式，包括信号、临界区、事件和互斥体。

## 1.5 实现共享内存的方式

内核为每一个进程维护一张页表，修改页表中虚拟页到物理页的映射，使得不同进程的内存地址空间映射到同一区域。Linux 通过 System V方式 shmat shmctl等挂载到共享内存区域。

## 线程基础

局部性原理：当我们访问到一个数据的时候大概率会访问到相邻位置的数据，每次缓存会缓存一整行，cacheLine缓存行，64个字节。当一个cpu缓存了一行数据的时候，发生修改，根据缓存一致性协议，会使另一个cpu缓存的数据失效，重新去内存读取数据。和volatile无关，volatile底层用到了锁，会马上去内存读取数据，这种协议不会马上去内存读取数据，不是很严格，这个底层用的是mesi，是cpu的底层实现。

逃逸分析：当前方法中新建的对象，不会逃脱掉当前的方法，只在当前的方法中使用，JIT即时编译器就会产生优化，就是所谓的逃逸分析，就会将当前的对象在栈上分配，不会在堆内存中分配。这样就会防止对象在堆中分配频繁的垃圾回收。

乱序存在的条件：

- as-if-serial
- 不影响单线程的最终一致性

### 1. 实现多线程的方法到底有几种？

1.不同的角度会有不同的方法

2.Oracle官方文档说的是2种方式，一种是实现Runnable接口，一种是继承Thread类。

3.准确的讲，创建线程只有一种方式就是构造Thread类，而实现线程的执行单元有两种方式

​	方法一：实现Runnable接口的run方法，并把Runnbale实例传给Thread类

​	方法二：重写Thread的run方法。

4.比如一个Timmer定时器类，一个Lamda表达式，一个内部类，线程池等方式都可以实现线程，但是本质上都是构造一个Thread类。

5.本质上只有一种构造Thread类，可以通过实现Runnable接口，重写Thread类的run方法。另外还可以通过线程池等方式来创建线程。

- 哪种实现方式更好？

  实现Runnable更好。从代码架构角度看，Run方法应该和Thread类解耦。继承Thread类的话每次都要新建一个线程，损耗会比较大，需要每次都创建销毁线程。而使用Runnable接口的话就可以反复使用同一个线程比如使用线程池。由于继承了Thread，就不能继承其他的类了，这样失去了可扩展性。

- 同时执行两种方法会怎么样？

  会只执行继承thread的run方法。当使用Runnable的run方法的时候会将Runnable传递给Thread类的run方法中，而继承thread类重写了run方法，之前的run方法就被覆盖掉了。

### 2. 为什么要使用多线程？

在刚开始解除到多线程的时候，我简单认为多线程就是为了提高性能的。后来了解的多了才发现，多线程其实并不一定能提升性能，甚至有的时候为了保证线程安全还会影响性能。多线程的应用主要有以下几个优点：

- **避免阻塞浪费大量时间：** 这里可以利用多线程BIO实现思想来解释一下多线程这个优点。假设现在场景是在BIO模式下客户端通过HTTP请求服务端，经过tcp连接之后，服务端一直在等待客户端进行数据的传输，如果客户端一直没有发送数据，那么在单线程模式下，这个响应会被阻塞住，直到接收到客户端的数据为止，这一段时间处理器的大量运行时间被闲置了。而如果我们利用多线程模型，在链接建立完成进入阻塞状态的时候，就可以创建一个新的线程对该连接进行监控，在子线程获取到CPU的时间时对客户端传输的数据进行处理，一但发生阻塞就再次切换线程，执行别的事务。此时就可以大大提高CPU的运行效率。

- **异步调用：** 单线程模型中事件的执行是顺序执行的，下一个操作必须等待前一个操作完成后才能执行，而如果前一个操作非常耗时，就会影响下一个操作的效率。此时可以使用多线程进行异步调用，比如我们创建一个工单时，需要向表中插入数据，如果数据级联的表很多，数据量很大，可能较为耗时，此时我们可以创建一个新的线程去执行插入的操作，当前线程先返回创建结果，继续下一个操作，以此来提高执行效率。

- 提高性能：

  在一定的前提下，多线程确实可以提高程序的性能，但不是绝对的。主要需要满足一下几种情况：

  1. 任务需要具备可拆分性，也就是并发性。一个任务可以拆分成多个子任务，才有多线程的必要。可拆分的条件是比较严格的，如果一个操作依赖另外一个操作的结果，那么即使使用多线程也不会带来性能上的提升。
  2. 只有当CPU性能是处理任务的瓶颈时，多线程才能带来性能的提升。如果一系列操作的性能瓶颈是磁盘的IO速度，那么即使使用多线程，也是无法提高性能的。
  3. 需要CPU有多个核心。多线程和多核心CPU的关系有点像厨师和灶台，一个线程是一个厨师，一个CPU核心是一个灶台，只有多个灶台的情况下，厨师才可以并发炒菜。否则还是需要一堆厨师排队等待一个灶台进行使用。



### 1.什么是线程死锁?如何避免死锁?

多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放

1. 破坏互斥条件
2. 破坏请求与保持条件
3. 破坏不剥夺条件
4. 破坏循环等待条件

### 2. volatile的作用

volatile关键字可以防止JVM的指令重排，还有一个重要作用就是保证变量的可见性，因为CPU具有L1，L2，L3缓存，volatile关键字可以保证被修改的元素内容直接写入到主内存中，根据缓存一致性协议使其他工作内存里缓存了该共享变量的地址数据无效，从而实现内存可见性。

### 3.Atomic类如何保证原子性（CAS操作）

依赖于UnSafe类，实现原子类，Unsafe类是由native方法实现的。

CAS需要有3个操作数：内存地址V，旧的预期值A，即将要更新的目标值B。

CAS指令执行时，当且仅当内存地址V的值与预期值A相等时，将内存地址V的值修改为B，否则就什么都不做。整个比较并替换的操作是一个原子操作。

由于volatile关键字不具有原子性，当i++操作时会产生问题，所以引入CAS。AtomicInteger。

1.ABA问题 ，利用客观锁加版本号解决。

2.循环时间长开销大。利用自旋次数或超时时间解决。

3.只能保证一个变量的原子操作 利用锁来解决

### 4.synchronized和Lock的区别

- synchronized是Java内置的关键字，在JVM层面，Lock是个Java类。
- synchronized 可以给类、方法、代码块加锁；而 lock 只能给代码块加锁。
- synchronized 不需要手动获取锁和释放锁，使用简单，发生异常会自动释放锁，不会造成死锁；而 lock 需要自己加锁和释放锁，如果使用不当没有 unLock()去释放锁就会造成死锁。
- 通过 Lock 可以知道有没有成功获取锁，而 synchronized 却无法办到。

### 5.线程之间如何通信？

- volatile关键字
- synchronized
- Lock下的等待/通知机制实现

### 类锁和方法锁的区别

**对象锁(方法)是用来控制实例方法之间的同步，类锁是用来控制静态方法（或静态变量互斥体）之间的同步。**　

**对象锁(方法锁)**，是针对一个对象的，它只在该对象的某个内存位置声明一个标识该对象是否拥有锁，所以它只会锁住当前的对象，一般一个对象锁是对一个非静态成员变量进行synchronized修饰，或者对一个非静态成员方法进行synchronized进行修饰，对于对象锁，不同对象访问同一个被synchronized修饰的方法的时候不会阻塞

**类锁**是锁住整个类，当有多个线程来声明这个类的对象时候将会被阻塞，直到拥有这个类锁的对象被销毁或者主动释放了类锁，这个时候在被阻塞的线程被挑选出一个占有该类锁，声明该类的对象。其他线程继续被阻塞住。

### 6.synchonied原理

monitor enter：

每个对象有一个监视器锁（monitor）。当monitor被占用时就会处于锁定状态，线程执行monitor enter指令时尝试获取monitor的所有权。

1、如果monitor的进入数为0，则该线程进入monitor，然后将进入数设置为1，该线程即为monitor的所有者。

2、如果线程已经占有该monitor，只是重新进入，则进入monitor的进入数加1

3、如果其他线程已经占用了monitor，则该线程进入阻塞状态，直到monitor的进入数为0，再重新尝试获取monitor的所有权。

monitor exit：

执行monitorexit的线程必须是objectref所对应的monitor的所有者。

指令执行时，monitor的进入数减1，如果减1后进入数为0，那线程退出monitor，不再是这个monitor的所有者。其他被这个monitor阻塞的线程可以尝试去获取这个 monitor 的所有权。 

### 7.如果一个线程发生异常没有捕获会发生什么？

Thread类中有一个`dispatchUncaughtException`方法,这个方法的作用是分发异常信息到正确的`UncaughtExceptionHandler`。当线程运行中出现了未捕获的异常，JVM会调用线程的这个方法，来寻找一个`UncaughtExceptionHandler`处理异常。

`getUncaughtExceptionHandler`的获取逻辑是，如果此线程的`uncaughtExceptionHandler`属性不为`null`,则分发异常到线程自己的`uncaughtExceptionHandler`，否则将异常分发给此线程所在的线程组。

## 锁

> 锁的状态总共有四种：无锁状态、偏向锁、轻量级锁和重量级锁

### 1.重量级锁

通过一个叫作监视器锁来实现，监视器锁依赖于操作系统的底层MutexLock实现。操作系统实现线程间的切换要从用户态切换到内核态，成本很高。

### 2.轻量级锁

轻量级锁所适应的场景是线程交替执行同步块的情况，如果存在同一时间访问同一锁的情况，就会导致轻量级锁膨胀为重量级锁。

#### 轻量级锁的加锁过程

（1）在代码进入同步块的时候，如果同步对象锁状态为无锁状态（锁标志位为“01”状态，是否为偏向锁为“0”），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝，官方称之为 Displaced Mark Word。

（2）拷贝对象头中的Mark Word复制到锁记录中。

（3）拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，并将Lock record里的owner指针指向object mark word。如果更新成功，则执行步骤（4），否则执行步骤（5）。

（4）如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为“00”，即表示此对象处于轻量级锁定状态。

（5）如果这个更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行。否则说明多个线程竞争锁，轻量级锁就要膨胀为重量级锁，锁标志的状态值变为“10”，Mark Word中存储的就是指向重量级锁（互斥量）的指针，后面等待锁的线程也要进入阻塞状态。 而当前线程便尝试使用自旋来获取锁，自旋就是为了不让线程阻塞，而采用循环去获取锁的过程。

#### 解锁过程：

（1）通过CAS操作尝试把线程中复制的Displaced Mark Word对象替换当前的Mark Word。

（2）如果替换成功，整个同步过程就完成了。

（3）如果替换失败，说明有其他线程尝试过获取该锁（此时锁已膨胀），那就要在释放锁的同时，唤醒被挂起的线程。

### 3.偏向锁

偏向锁的思想是偏向于让第一个获取锁对象的线程，这个线程在之后获取该锁就不再需要进行同步操作，甚至连 CAS 操作也不再需要。

当锁对象第一次被线程获得的时候，进入偏向状态，标记为 1 01。同时使用 CAS 操作将线程 ID 记录到 Mark Word 中，如果 CAS 操作成功，这个线程以后每次进入这个锁相关的同步块就不需要再进行任何同步操作。

当有另外一个线程去尝试获取这个锁对象时，偏向状态就宣告结束，此时撤销偏向（Revoke Bias）后恢复到未锁定状态或者轻量级锁状态。

　　引入偏向锁是为了在无多线程竞争的情况下尽量减少不必要的轻量级锁执行路径，因为轻量级锁的获取及释放依赖多次CAS原子指令，而偏向锁只需要在置换ThreadID的时候依赖一次CAS原子指令（由于一旦出现多线程竞争的情况就必须撤销偏向锁，所以偏向锁的撤销操作的性能损耗必须小于节省下来的CAS原子指令的性能消耗）。上面说过，轻量级锁是为了在线程交替执行同步块时提高性能，而偏向锁则是在只有一个线程执行同步块时进一步提高性能。

#### 偏向锁获取过程：

　　（1）访问Mark Word中偏向锁的标识是否设置成1，锁标志位是否为01——确认为可偏向状态。

　　（2）如果为可偏向状态，则测试线程ID是否指向当前线程，如果是，进入步骤（5），否则进入步骤（3）。

　　（3）如果线程ID并未指向当前线程，则通过CAS操作竞争锁。如果竞争成功，则将Mark Word中线程ID设置为当前线程ID，然后执行（5）；如果竞争失败，执行（4）。

　　（4）如果CAS获取偏向锁失败，则表示有竞争。当到达全局安全点（safepoint）时获得偏向锁的线程被挂起，偏向锁升级为轻量级锁，然后被阻塞在安全点的线程继续往下执行同步代码。

　　（5）执行同步代码。

#### 偏向锁释放：

偏向锁的撤销在上述第四步骤中有提到**。**偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动去释放偏向锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态，撤销偏向锁后恢复到未锁定（标志位为“01”）或轻量级锁（标志位为“00”）的状态。

### 4.自旋锁

互斥同步进入阻塞状态的开销都很大，应该尽量避免。在许多应用中，共享数据的锁定状态只会持续很短的一段时间。自旋锁的思想是让一个线程在请求一个共享数据的锁时执行忙循环（自旋）一段时间，如果在这段时间内能获得锁，就可以避免进入阻塞状态。

自旋锁虽然能避免进入阻塞状态从而减少开销，但是它需要进行忙循环操作占用 CPU 时间，它只适用于共享数据的锁定状态很短的场景。

在 JDK 1.6 中引入了自适应的自旋锁。自适应意味着自旋的次数不再固定了，而是由前一次在同一个锁上的自旋次数及锁的拥有者的状态来决定。



## 线程池

### 1.为什么要使用线程池？

**池化技术的思想主要是为了减少每次获取资源的消耗，提高对资源的利用率。**

- 降低资源消耗，通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
- 提高响应速度，当任务到达时，任务可以不需要的等到线程创建就能立即执行。
- 提高线程的可管理性，使用线程池可以进行统一的分配，调优和监控。

### 2.核心线程池？以及ThreadPoolExecutor的参数？

#### 线程池类型

1. newFixedThreaPool(int nThread):指定工作线程数量的线程池，全部为核心线程
2. newCachedThreaPool():一个用来处理大量段时间工作任务的线程池，全部为普通线程池，执行速度较快较小的线程
3. newSigleThreadExecutor()：核心和最大线程数都为1。每次只执行一个线程，多余的先存储到工作队列。

- **`corePoolSize` :** 核心线程数线程数定义了最小可以同时运行的线程数量。
- **`maximumPoolSize` :** 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。
- **`workQueue`:** 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。

`ThreadPoolExecutor`其他常见参数:

- **`keepAliveTime`**:当普通线程池中的线程数量大于 `corePoolSize`核心线程池数量 的时候，如果这时没有新的任务提交，普通线程不会立即销毁，而是会等待，直到等待的时间超过了 `keepAliveTime`才会被回收销毁；
- **`unit`** : `keepAliveTime` 参数的时间单位。
- **`threadFactory`** :executor 创建新线程的时候会用到。
- **`handler`** :饱和策略。即对拒绝任务的处理策略。

### 当线程池满的时候会发生什么

如果创建新线程将使当前运行的线程超出maximumPoolSize，任务将被拒绝，并调用RejectedExecutionHandler.rejectedExecution()方法，抛出异常。

#### 线程池的拒绝策略

ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。 ThreadPoolExecutor.DiscardPolicy：丢弃任务，但是不抛出异常。 ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新提交被拒绝的任务 ThreadPoolExecutor.CallerRunsPolicy：由调用线程（提交任务的线程）处理该任务

### 3.ThreadPoolExecutor的工作流程?

1. 如果线程池中运行的线程少于corePoolSize设定值，则创建新的线程来执行任务，即使线程池中其他线程是空闲的。
2. 如果线程池中的线程数量大于等于corePoolSize并且小于maximumPoolSize，队列workQueue未满，则将新添加的任务放到workQueue中。
3. 如果线程池中的线程数量大于等于corePoolSize并且小于maximumPoolSize，队列workQueue已满，则会创建新的线程来处理被添加的任务。
4. 如果线程池设置的corePoolSize和maximumPoolSize相同，则线程池的大小是固定的，此时新任务提交，若队列workQueue未满，则将新添加的任务放到workQueue中。
5. 如果线程池中的线程数量大于等于了maximumPoolSize，就执行拒绝策略handler 。

### 4.线程安全

- 线程安全：当多个线程同时访问一个对象时，如果不用考虑这些线程在运行时环境下的调度和交替执行，也不需要进行额外的同步，或者在调用方进行任何其他的协调操作，调用这个对象的行文都可以获得正确的结果，那就称这个对象时线程安全的。
- 为什么会出现线程安全问题：多线程操作共享资源时，导致共享资源出现错乱就是线程安全问题。其本质上是因为每个线程都有自己独立的工作空间。
  这里先介绍下JMM，即Java内存模型（注意不是运行时数据区模型，不一样）。JMM中将内存分为主内存和工作内存，主内存属于数据共享的区域，存储的实例对象和数据信息。每个线程会有自己的工作内存，存储当前方法的所有本地变量信息，线程的工作内存对其他线程不可见。线程在工作时并不是直接在主存上直接操作的，而是会将数据从主存拷贝一份到工作内存中，操作完成后刷新回主内存。
  所以在这一过程中，多个线程对数据的操作都是在自己的工作内存当中的，当多个线程操作同一对象，最后刷新回主存时，可能发生数据不一致现象，就会出现线程安全问题。



## ThreadLocal

>  `ThreadLocal`对象可以提供线程局部变量，每个线程`Thread`拥有一份自己的**副本变量**，多个线程互不干扰。

`Thread`类有一个类型为`ThreadLocal`.`ThreadLocalMap`的实例变量`threadLocals`，也就是说每个线程有一个自己的`ThreadLocalMap`。

`ThreadLocalMap`有自己的独立实现，可以简单地将它的`key`视作`ThreadLocal`，`value`为代码中放入的值（实际上`key`并不是`ThreadLocal`本身，而是它的一个**弱引用**）。

每个线程在往`ThreadLocal`里放值的时候，都会往自己的`ThreadLocalMap`里存，读也是以`ThreadLocal`作为引用，在自己的`map`里找对应的`key`，从而实现了**线程隔离**。

`ThreadLocalMap`有点类似`HashMap`的结构，只是`HashMap`是由**数组+链表**实现的，而`ThreadLocalMap`中并没有**链表**结构。

我们还要注意`Entry`， 它的`key`是``ThreadLocal`<?> k` ，继承自`WeakReference， 也就是我们常说的弱引用类型。

### GC 之后key是否为null？

不为null

- **强引用**：我们常常new出来的对象就是强引用类型，只要强引用存在，垃圾回收器将永远不会回收被引用的对象，哪怕内存不足的时候
- **软引用**：使用SoftReference修饰的对象被称为软引用，软引用指向的对象在内存要溢出的时候被回收
- **弱引用**：使用WeakReference修饰的对象被称为弱引用，只要发生垃圾回收，若这个对象只被弱引用指向，那么就会被回收
- **虚引用**：虚引用是最弱的引用，在 Java 中使用 PhantomReference 进行定义。虚引用中唯一的作用就是用队列接收对象即将死亡的通知



## 参考文献

1.[synchorized原理](https://www.cnblogs.com/paddix/p/5367116.html)

